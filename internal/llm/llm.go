package llm

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"gitter/internal/config"
	"net/http"
	"time"
)

// LLMClient is the interface for a client that can generate commit messages.
type LLMClient interface {
	GenerateCommitMessage(diff string, userMessage string) (string, error)
}

// NewLLMClient returns an LLM client based on the provided config.
func NewLLMClient(cfg config.Config) (LLMClient, error) {
	switch cfg.Provider {
	case "openai":
		return &OpenAIClient{
			APIKey:  cfg.APIKey,
			BaseURL: "https://api.openai.com/v1",
		}, nil
	case "":
		return nil, fmt.Errorf("no LLM provider configured")
	default:
		return nil, fmt.Errorf("unsupported LLM provider: %s", cfg.Provider)
	}
}

// OpenAIClient is a client for the OpenAI API.
type OpenAIClient struct {
	APIKey  string
	BaseURL string
}

// openAIRequest represents the request body for the OpenAI Chat Completions API.
type openAIRequest struct {
	Model    string    `json:"model"`
	Messages []message `json:"messages"`
}

// message is a single message in the chat history.
type message struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

// openAIResponse is the response from the OpenAI API.
type openAIResponse struct {
	Choices []struct {
		Message struct {
			Content string `json:"content"`
		} `json:"message"`
	} `json:"choices"`
	Error *struct {
		Message string `json:"message"`
	} `json:"error,omitempty"`
}

// GenerateCommitMessage generates a commit message using the OpenAI API.
func (c *OpenAIClient) GenerateCommitMessage(diff string, userMessage string) (string, error) {
	if c.APIKey == "" {
		return "", fmt.Errorf("OpenAI API key is not set")
	}

	prompt := fmt.Sprintf(`You are an expert at writing conventional git commit messages.
Based on the following user prompt and git diff, generate a concise and descriptive commit message.
The message should follow the conventional commit format (e.g., 'feat: add new feature' or 'fix: resolve a bug').
The first line should be a short summary (the title), followed by a blank line, and then a more detailed description (the body) if necessary.
Do not include the 'Changes:' section with file stats in your output.

User Prompt: "%s"

Git Diff:
%s`, userMessage, diff)

	reqBody := openAIRequest{
		Model: "gpt-3.5-turbo", // A common and effective model
		Messages: []message{
			{Role: "system", Content: "You are a helpful assistant that generates git commit messages."},
			{Role: "user", Content: prompt},
		},
	}

	reqBytes, err := json.Marshal(reqBody)
	if err != nil {
		return "", fmt.Errorf("could not marshal OpenAI request: %w", err)
	}

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	requestURL := fmt.Sprintf("%s/chat/completions", c.BaseURL)
	req, err := http.NewRequestWithContext(ctx, "POST", requestURL, bytes.NewBuffer(reqBytes))
	if err != nil {
		return "", fmt.Errorf("could not create OpenAI request: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+c.APIKey)

	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return "", fmt.Errorf("could not send request to OpenAI: %w", err)
	}
	defer resp.Body.Close()

	var apiResp openAIResponse
	if err := json.NewDecoder(resp.Body).Decode(&apiResp); err != nil {
		return "", fmt.Errorf("could not decode OpenAI response: %w", err)
	}

	if resp.StatusCode != http.StatusOK {
		if apiResp.Error != nil {
			return "", fmt.Errorf("OpenAI API error (%s): %s", resp.Status, apiResp.Error.Message)
		}
		return "", fmt.Errorf("OpenAI API request failed with status: %s", resp.Status)
	}

	if len(apiResp.Choices) == 0 {
		return "", fmt.Errorf("no commit message generated by OpenAI")
	}

	return apiResp.Choices[0].Message.Content, nil
}
